# Configuration file for prediction module
# Copy this to config.yaml and fill in your credentials

# API Keys
api_keys:
  github_token: ""  # Get from https://github.com/settings/tokens
  anthropic_key: ""  # Get from https://console.anthropic.com/

# Model Configuration
models:
  github_default: "gpt-4o-mini"  # Options: gpt-4o-mini, gpt-4o, claude-3.5-sonnet, meta-llama-3.1-405b, phi-3.5
  anthropic_default: "claude-3-haiku-20240307"  # Options: claude-3-haiku-20240307, claude-3-sonnet-20240229, claude-3-opus-20240229

# Analysis Settings
analysis:
  max_records: 10  # Number of sample records to include in analysis
  temperature: 0.7  # Model temperature (0.0-1.0)
  max_tokens: 1024  # Maximum tokens in response
